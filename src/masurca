#!/usr/bin/env perl
# SuperRead pipeline
# Copyright (C) 2012  Genome group at University of Maryland.
# 
# This program is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

#This script reads the the config file and runs the full super reads pipeline
#config file format:
#
#DATA
#PE= id mean stdev fastq_forward fastq_reverse
#JUMP= id mean stdev fastq_forward fastq_reverse 
#OTHER=frag1.frg
#END
#
#PARAMETERS
#KMER_COUNT_THRESHOLD=1
#NUM_THREADS=24
#JF_SIZE=2000000000
#EXTEND_JUMP_READS=0
#END
#

use strict;
use warnings;
use Env qw(@PATH @LD_LIBRARY_PATH);
use File::Spec;
use Getopt::Long;

use FindBin qw($RealBin);
use lib $RealBin;

use MasurcaConf;

#global variables
my (@pe_files, @sj_files);
my ($list_pe_files, $list_jump_files);
my $list_frg_files = "";
my $rerun_pe          = 0;
my $rerun_sj          = 0;

# Those seem to be constants
my $WINDOW                  = 10;
my $MAX_ERR_PER_WINDOW      = 3;

my %used_library_ids;

# Options to masurca script
my $assembly_script = "assemble.sh";
my $generate_default;
my $skip_checking;
my @prep_path;
my @prep_ld;
my $help;

my $usage = "USAGE: $0 <config_file>";
my $help_str = <<"EOS" ;
Create the assembly script from a MaSuRCA configuration file. An
sample configuration file can be generated with the -g switch. The
assembly script will run the assembly proper.

Options:
 -o, --output              Assembly script ($assembly_script)
 -g, --generate            Generate example configuration file
 -p, --path                Prepend to PATH in assembly script
 -l, --ld-library-path     Prepend to LD_LIBRARY_PATH in assembly script
     --skip-checking       Skip checking availability of other executables
 -h, --help                This message
EOS
    ;


# Like die, but don't print backtrace like information
my $config_file;
sub fail {
  print(STDERR "Error");
  if(defined($config_file) &&  defined($_[1])) {
    print(STDERR " line $_[1] of configuration file '$config_file':\n");
  } else {
    print(STDERR ": ");
  }
  chomp($_[0]);
  print(STDERR $_[0], "\n");
  exit(1);
}

sub rename_reads {
  my ($type, @read_info) = @_;
  my @res;
  my $out = "meanAndStdevByPrefix.$type.txt";
  my $do_wait = 0;

  print FILE "log 'Processing $type library reads'\n";
  print FILE "rm -rf $out\n";
  foreach my $v (@read_info){
    my ($name, $mean, $stdev, $fr, $rr) = split(" ", $v);
    my $renamed = "$name.renamed.fastq";
    ($mean, $stdev) = (500, 100) if($type eq "sj");
    push(@res, $renamed);
    print FILE "echo '$name $mean $stdev' >> $out\n";
    next if(-e $renamed);
    $do_wait = 1;
    $rerun_pe = 1;
    $rerun_sj = 1;
    print( FILE "run_bg rename_filter_fastq '$name' <(exec expand_fastq '$fr' | awk '{if(length(\$0>200)) print substr(\$0,1,200); else print \$0;}') ",
           defined($rr) ? "<(exec expand_fastq '$rr' | awk '{if(length(\$0>200)) print substr(\$0,1,200); else print \$0;}' )" : "''",
           " > '$renamed'\n");
  }
  return @res;
}

sub estimate_optimal_kmer{
  my ($filelist, $name) = @_;
  my $max_kmer=127;
  if($name eq "KMER_J"){
  print FILE "$name=31\n";
  }else{
print FILE "$name=`for f in $filelist;do head -n 80000 \$f |tail -n 40000;done | perl -e 'while(\$line=<STDIN>){\$line=<STDIN>;chomp(\$line);push(\@lines,\$line);\$line=<STDIN>;\$line=<STDIN>}\$min_len=100000;\$base_count=0;foreach \$l(\@lines){\$base_count+=length(\$l);push(\@lengths,length(\$l));\@f=split(\"\",\$l);foreach \$base(\@f){if(uc(\$base) eq \"G\" || uc(\$base) eq \"C\"){\$gc_count++}}} \@lengths =sort {\$b <=> \$a} \@lengths; \$min_len=\$lengths[int(\$\#lengths*.75)];  \$gc_ratio=\$gc_count/\$base_count;\$kmer=0;if(\$gc_ratio<0.5){\$kmer=int(\$min_len*.7);}elsif(\$gc_ratio>=0.5 && \$gc_ratio<0.6){\$kmer=int(\$min_len*.5);}else{\$kmer=int(\$min_len*.33);} \$kmer=31 if(\$kmer<31); \$kmer=$max_kmer if(\$kmer>$max_kmer); print \$kmer'`\n";
}
}

sub get_MIN_Q_CHAR{
  my $filelist=$_[0];
  print FILE "MIN_Q_CHAR=`cat $filelist |head -n 50000 | awk 'BEGIN{flag=0}{if(\$0 ~ /^\\+/){flag=1}else if(flag==1){print \$0;flag=0}}'  | perl -ne 'BEGIN{\$q0_char=\"\@\";}{chomp;\@f=split \"\";foreach \$v(\@f){if(ord(\$v)<ord(\$q0_char)){\$q0_char=\$v;}}}END{\$ans=ord(\$q0_char);if(\$ans<64){print \"33\\n\"}else{print \"64\\n\"}}'`\n";
  print FILE "save MIN_Q_CHAR\n";
  print FILE "echo MIN_Q_CHAR: \$MIN_Q_CHAR\n";
}

sub count_kmers_for_quorum {
  my ($filelist, $NUM_THREADS, $thresh) = @_;
  print FILE <<"EOS";
quorum_create_database -t $NUM_THREADS -s \$JF_SIZE -b 7 -m 24 -q \$((MIN_Q_CHAR + $thresh)) -o quorum_mer_db.jf $filelist
if [ $? != 0 ]; then
  fail Increase JF_SIZE in config file, the recommendation is to set this to genome_size*coverage/2
fi
EOS
}

sub check_exec {
  for my $e (@_) {
    system("$e --help >/dev/null 2>&1") == 0 or fail "$e not found or failed to run";
    print "$e OK\n";
  }
}

sub filter_jump {
  #globals that can be changed here: $rerun_pe, $rerun_sj
  #const globals:  $$config{NUM_THREADS}, $$config{EXTEND_JUMP_READS} LIMIT_JUMP_COVERAGE 
  my (%config) = @_;

  #creating super reads for filtering
  if($rerun_pe==1 || $rerun_sj==1 || not(-e "work2")){
    print FILE "rm -rf work2\n";
    $rerun_sj=1;
  }
  print FILE "createSuperReadsForDirectory.perl  -maxnodes 2000 -minreadsinsuperread 1 -l \$KMER_J -join-aggressive 1 -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.sj.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.jump.fasta -t $config{NUM_THREADS} -mikedebug work2 sj.cor.fa 1> super2.err 2>&1\n";

  #check if the super reads pipeline finished successfully
  print FILE "if [[ ! -e work2/superReads.success ]];then\n";
  print FILE "fail Super reads failed, check super2.err and files in ./work2/\n";
  print FILE "fi\n";

  #now, using read positions in super reads, we find out which mates got joined -- these are the ones that do not have the biotin in the middle, call them chimeric
  if(not(-e "chimeric_sj.txt")||$rerun_pe==1||$rerun_sj==1){
    print FILE "filter_alt.pl outtie < work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt >  chimeric_sj.txt \n";
    $rerun_sj=1;
  }

  #we also do initial redundancy filtering here, based on positions of reads in suoer reads
  if(not(-e "redundant_sj.txt")||$rerun_pe==1||$rerun_sj==1){
    print FILE "filter_redundancy.pl 2 < work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt > redundant_sj.txt\n";
    $rerun_sj=1;
  } 
  print FILE "echo 'Chimeric/Redundant jump reads:';wc -l  chimeric_sj.txt redundant_sj.txt;\n";

  #remove all chimeric and all redundant reads from sj.cor.fa
  if(not(-e "sj.cor.clean.rev.fa")||$rerun_pe==1||$rerun_sj==1){
    print FILE "extractreads.pl <(cat chimeric_sj.txt redundant_sj.txt | perl -e '{
		while(\$line=<STDIN>){
		chomp(\$line);
		\$h{\$line}=1
		}
		open(FILE,\$ARGV[0]);
		while(\$line=<FILE>){
		chomp(\$line);
		print \$line,\"\\n\" if(not(defined(\$h{\$line})));
		}
		}' <(awk '{
			prefix=substr(\$1,1,2); 
			readnumber=int(substr(\$1,3));  
			if(readnumber\%2==0){
				last_readnumber=readnumber; 
				last_prefix=prefix;
			}else{
				if(last_readnumber==readnumber-1 && last_prefix==prefix){
					print prefix\"\"last_readnumber\"\\n\"prefix\"\"readnumber;
				}
			}
			}' work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt)) sj.cor.fa 1 | putReadsIntoGroupsBasedOnSuperReads --super-read-sequence-file work2/superReadSequences.fasta --read-placements-file work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt > sj.cor.clean.fa\n";

    #here we perform another round of filtering bad mates
    print FILE "findReversePointingJumpingReads_bigGenomes.perl --jellyfish-hash-size \$JF_SIZE --kmer-step-size 5 --reads-file sj.cor.clean.fa --reads-for-kunitigs-file pe.cor.fa --reads-for-kunitigs-file sj.cor.fa --dir-to-change-to  work2.1 --dir-for-kunitigs work2.1 --min-kmer-len 41 --max-kmer-len 81 -t $config{NUM_THREADS} --maxnodes 1000 --kmer-step-size 10 1>findReversePointingJumpingReads.err 2>&1 \n";
        print FILE "extractreads_not.pl work2.1/readsToExclude.txt sj.cor.clean.fa 1 > sj.cor.clean2.fa\n";
    print FILE "echo Found extra chimeric mates: \n";
    print FILE "wc -l work2.1/readsToExclude.txt\n";
    print FILE "rm -f sj.cor.clean.rev.fa\n";
    foreach my $v (@{$config{JUMP_INFO}}) {
      my @f        = split(" ", $v);
      my $if_innie = "";
      $if_innie    = " | reverse_complement " if($f[1]>0);
      print FILE "grep --text -A 1 '^>$f[0]' sj.cor.clean2.fa | grep --text -v '^\\-\\-' $if_innie >> sj.cor.clean.rev.fa\n";
    }
    $rerun_sj=1;
  }

  #here we extend the jumping library reads if they are too short
  if(not($config{SOAP_ASSEMBLY})){
    if(not(-e "sj.cor.ext.fa")||$rerun_pe==1||$rerun_sj==1){      
      $rerun_sj=1;
      if($config{EXTEND_JUMP_READS} == 1){
        print FILE "createSuperReadsForDirectory.perl -jumplibraryreads -minreadsinsuperread 1 -l \$KMER_J -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.sj.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.jump.fasta -t $config{NUM_THREADS} -mikedebug work3 sj.cor.clean.rev.fa 1> super2.err 2>&1\n";

        #check if the super reads pipeline finished successfully
        print FILE "if [[ ! -e work3/superReads.success ]];then\n";
        print FILE "fail Super reads failed, check super2.err and files in ./work2/\n";
        print FILE "fi\n";

        print FILE "ln -sf work3/superReadSequences.jumpLibrary.fasta sj.cor.ext.fa\n";
      }else{
	print FILE "ln -sf sj.cor.clean.rev.fa sj.cor.ext.fa\n";
      }
    }

    #here we create the frg files for CA from the jump libraries: each jump library will contribute one jump frg file and one additional frg file of linking information from "chimers"
    print FILE "log 'Creating FRG files'\n";
    print FILE "rm -rf compute_jump_coverage.txt\n";
    
    foreach my $v (@{$config{JUMP_INFO}}) {
      my @f = split(" ", $v);
      print FILE "echo -n \"$f[1] \" >> compute_jump_coverage.txt\n";
      print FILE "grep --text -A 1 '^>$f[0]' sj.cor.ext.fa | grep --text -v '^\\-\\-' > $f[0].tmp\n";
      print FILE "error_corrected2frg $f[0] ",abs($f[1])," $f[2] 2000000000 $f[0].tmp | grep --text '^{LKG' |wc -l >> compute_jump_coverage.txt\n";
    }
    print FILE "JUMP_BASES_COVERED=`awk 'BEGIN{b=0}{b+=\$1*\$2;}END{print b}' compute_jump_coverage.txt`\n";
    print FILE "save JUMP_BASES_COVERED\n";

    #here we reduce jump library coverage: we know the genome size (from k-unitigs) and JUMP_BASES_COVERED contains total jump library coverage :)
    foreach my $v (@{$config{JUMP_INFO}}) {
      my @f = split(" ", $v);
      $list_frg_files .= "$f[0].cor.clean.frg ";
      print FILE "grep --text -A 1 '^>$f[0]' sj.cor.ext.fa | grep --text -v '^\\-\\-' | sample_mate_pairs.pl $config{LIMIT_JUMP_COVERAGE} `perl -e 'print int('\$JUMP_BASES_COVERED'/'\$ESTIMATED_GENOME_SIZE'/1.6)'` 1 > $f[0].tmp\n";
      print FILE "error_corrected2frg $f[0] ",abs($f[1])," $f[2] 2000000000 $f[0].tmp > $f[0].cor.clean.frg\n";
      print FILE "rm -f $f[0].tmp\n";
    }
  }
}

sub create_pe_linking_mates {
  my (%config) = @_;

  foreach my $v (@{$config{PE_INFO}}){
    my @f=split(/\s+/,$v);
    $list_frg_files .= "$f[0].linking.frg ";
    if(not(-e "$f[0].linking.frg")||$rerun_pe==1){
      print FILE "grep --text -A 1 '^>$f[0]' pe.linking.fa | grep --text -v '^\\-\\-' | sample_mate_pairs.pl \$MAX_LINKING_MATES \$NUM_LINKING_MATES 1 > $f[0].tmp\n";
      print FILE "error_corrected2frg $f[0] $f[1] $f[2] 2000000000 $f[0].tmp > $f[0].linking.frg\n";
      print FILE "rm $f[0].tmp\n";
    }
  }
  print FILE "echo -n 'Linking PE reads '; cat ??.linking.frg | grep -c --text '^{FRG' \n";
}

sub runCA {
  my ($frg_files, $tmplist, %config) = @_;
  
  my ($ovlMerSize, $other_parameters) = (30, "doFragmentCorrection=0 doOverlapBasedTrimming=0 doExtendClearRanges=0 ovlMerSize=30");
  if(@{$config{OTHER_INFO}} || @{$config{MOLECULO_INFO}}) {
    ($ovlMerSize, $other_parameters) = (22, "doFragmentCorrection=1 doOverlapBasedTrimming=1 doExtendClearRanges=1 ovlMerSize=22");
  }

  if(not(-d "CA/7-0-CGW")|| $rerun_pe || $rerun_sj){
    print FILE "TOTAL_READS=`cat  *.frg | grep -c --text '^{FRG' `\n";
    print FILE "save TOTAL_READS\n";
    print FILE "ovlRefBlockSize=`perl -e '\$s=int('\$TOTAL_READS'/8); if(\$s>100000){print \$s}else{print \"100000\"}'`\n";
    print FILE "save ovlRefBlockSize\n";
    print FILE "ovlHashBlockSize=`perl -e '\$s=int('\$TOTAL_READS'/80); if(\$s>10000){print \$s}else{print \"10000\"}'`\n";
    print FILE "save ovlHashBlockSize\n";
    print FILE "ovlCorrBatchSize=\$ovlHashBlockSize\n";
    print FILE "save ovlCorrBatchSize\n";

    if(not(-d "CA/genome.ovlStore")|| $rerun_pe || $rerun_sj){
      print FILE "ovlMerThreshold=`jellyfish-2.0 histo -t $config{NUM_THREADS} k_u_hash_0 | awk '{thresh=75;if(\$1>1) {dist+=\$2;if(dist>int(\"'\$ESTIMATED_GENOME_SIZE'\")*0.98&&flag==0){if(\$1>thresh) thresh=\$1;flag=1}}}END{print thresh}'`\n";
      print FILE "echo ovlMerThreshold=\$ovlMerThreshold\n\n";
    }

    if(not(-e "CA/5-consensus/consensus.success")|| $rerun_pe || $rerun_sj){
      print FILE "runCA ovlMerThreshold=\$ovlMerThreshold gkpFixInsertSizes=0 $config{CA_PARAMETERS} jellyfishHashSize=\$JF_SIZE ovlRefBlockSize=\$ovlRefBlockSize ovlHashBlockSize=\$ovlHashBlockSize ovlCorrBatchSize=\$ovlCorrBatchSize stopAfter=consensusAfterUnitigger unitigger=bog -p genome -d CA merylThreads=$config{NUM_THREADS} frgCorrThreads=1 frgCorrConcurrency=$config{NUM_THREADS} cnsConcurrency=$config{NUM_CNS_THREADS} ovlCorrConcurrency=$config{NUM_THREADS} ovlConcurrency=$config{NUM_THREADS} ovlThreads=1 $other_parameters superReadSequences_shr.frg $frg_files   1> runCA1.out 2>&1\n";

      print FILE "if [[ -e \"CA/4-unitigger/unitigger.err\" ]];then\n";
      print FILE "echo \"Overlap/unitig success\"\n";
      print FILE "else\n";
      print FILE "fail Overlap/unitig failed, check output under CA/ and runCA1.out\n";
      print FILE "fi\n";

      print FILE "recompute_astat_superreads.sh genome CA \$PE_AVG_READ_LENGTH work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt\n";

      print FILE "NUM_SUPER_READS=`cat superReadSequences_shr.frg $tmplist | grep -c --text '^{FRG' `\n";
      print FILE "save NUM_SUPER_READS\n";
      print FILE "cd CA\n";
      print FILE "tigStore -g genome.gkpStore -t genome.tigStore 2 -d layout -U | tr -d '-' | awk 'BEGIN{print \">unique unitigs\"}{if(\$1 == \"cns\"){seq=\$2}else if(\$1 == \"data.unitig_coverage_stat\" && \$2>=5){print seq\"N\"}}' | jellyfish-2.0 count -L 2 -C -m $ovlMerSize -s \$ESTIMATED_GENOME_SIZE -t $config{NUM_THREADS} -o unitig_mers /dev/fd/0\n";
      print FILE "cat <(overlapStore -b 1 -e \$NUM_SUPER_READS -d genome.ovlStore  | awk '{if(\$1<'\$NUM_SUPER_READS' && \$2<'\$NUM_SUPER_READS') print \$0}'|filter_overlap_file -t $config{NUM_THREADS} <(gatekeeper -dumpfastaseq genome.gkpStore ) unitig_mers /dev/fd/0) <(overlapStore -d genome.ovlStore | awk '{if(\$1>='\$NUM_SUPER_READS' || \$2>='\$NUM_SUPER_READS') print \$1\" \"\$2\" \"\$3\" \"\$4\" \"\$5\" \"\$6\" \"\$7}')  |convertOverlap -b -ovl > overlaps.ovb\n";
      print FILE "rm -rf 4-unitigger 5-consensus genome.tigStore genome.ovlStore\n";
      print FILE "overlapStore -c genome.ovlStore -M 4096 -t $config{NUM_THREADS} -g genome.gkpStore overlaps.ovb 1>overlapstore.err 2>&1\n";
      print FILE "cd ..\n";
      print FILE "runCA ovlMerThreshold=\$ovlMerThreshold gkpFixInsertSizes=0 $config{CA_PARAMETERS} jellyfishHashSize=\$JF_SIZE ovlRefBlockSize=\$ovlRefBlockSize ovlHashBlockSize=\$ovlHashBlockSize ovlCorrBatchSize=\$ovlCorrBatchSize stopAfter=consensusAfterUnitigger unitigger=bog -p genome -d CA merylThreads=$config{NUM_THREADS} frgCorrThreads=1 frgCorrConcurrency=$config{NUM_THREADS} cnsConcurrency=$config{NUM_CNS_THREADS} ovlCorrConcurrency=$config{NUM_THREADS} ovlConcurrency=$config{NUM_THREADS} ovlThreads=1 $other_parameters superReadSequences_shr.frg $frg_files   1> runCA2.out 2>&1\n";

      print FILE "if [[ -e \"CA/5-consensus/consensus.success\" ]];then\n";
      print FILE "echo \"Unitig consensus success\"\n";
      print FILE "else\n";
      print FILE "echo \"Fixing unitig consensus...\"\n";
      print FILE "mkdir CA/fix_unitig_consensus\n";
      print FILE "cd CA/fix_unitig_consensus\n";
      print FILE "cp `which fix_unitigs.sh` .\n";
      print FILE "./fix_unitigs.sh genome \n";
      print FILE "cd ../../\n";
      print FILE "fi\n";

      print FILE "recompute_astat_superreads.sh genome CA \$PE_AVG_READ_LENGTH work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt\n";
    }
  }

  print FILE "runCA $config{CA_PARAMETERS} unitigger=bog -p genome -d CA cnsConcurrency=$config{NUM_CNS_THREADS} computeInsertSize=0 $other_parameters 1>runCA3.out 2>&1\n";
  print FILE "if [[ -e \"CA/9-terminator/genome.qc\" ]];then\n";
  print FILE "echo \"CA success\"\n";
  print FILE "else\n";
  print FILE "fail CA failed, check output under CA/ and runCA3.out\n";
  print FILE "fi\n";
}


#parsing config file
GetOptions("o|output=s"          => \$assembly_script,
           "g|generate"          => \$generate_default,
           "p|path=s"            => \@prep_path,
           "l|ld-library-path=s" => \@prep_ld,
           "skip-checking"       => \$skip_checking,
           "h|help"              => \$help) or fail $usage;

if($help) {
  print "$help_str";
  exit(0);
}
fail $usage if @ARGV != 1;
$config_file = $ARGV[0];

if($generate_default) {
  fail "Refusing to overwrite existing configuration file '$config_file'" if(-e $config_file);
  open(FILE, ">", $config_file) or fail "Error opening configuration file '$config_file': $!";
  print(FILE MasurcaConf::default_config);
  close(FILE);
  exit(0);
}

my %config = MasurcaConf::parse($config_file);
fail("no read data files specified") if(@{$config{PE_INFO}} + @{$config{JUMP_INFO}} + @{$config{OTHER_INFO}} == 0);

if(@prep_path) {
  unshift(@PATH, @prep_path);
} else {
  unshift(@PATH, $RealBin, $RealBin . "/../CA/Linux-amd64/bin");
}
unshift(@LD_LIBRARY_PATH, @prep_ld) if @prep_ld;

unless($skip_checking) {
  print "Verifying PATHS...\n";
  my @progs=("jellyfish-2.0", "runCA", "createSuperReadsForDirectory.perl");
  push(@progs,("nucmer","mega_reads_assemble.sh")) if(@{$config{PACBIO_INFO}});
  push(@progs, "SOAPdenovo-63mer") if($config{SOAP_ASSEMBLY});
  &check_exec(@progs);
}

fail ("no PE data specified") if(@{$config{PE_INFO}} == 0);

print("creating script file for the actions...");

my $config_abs_path = File::Spec->rel2abs($config_file);
my $cmd_abs_path = File::Spec->rel2abs(__FILE__);

open(FILE,">", $assembly_script) or fail "Can't open output file '$assembly_script': $!";
print FILE <<"EOS";
#!/bin/bash

# $assembly_script generated by masurca
CONFIG_PATH="$config_abs_path"
CMD_PATH="$cmd_abs_path"

# Test that we support <() redirection
(eval "cat <(echo test) >/dev/null" 2>/dev/null) || {
  echo >&2 "ERROR: The shell used is missing important features."
  echo >&2 "       Run the assembly script directly as './\$0'"
  exit 1
}

# Parse command line switches
while getopts ":rc" o; do
  case "\${o}" in
    c)
    echo "configuration file is '\$CONFIG_PATH'"
    exit 0
    ;;
    r)
    echo "Rerunning configuration"
    exec perl "\$CMD_PATH" "\$CONFIG_PATH"
    echo "Failed to rerun configuration"
    exit 1
    ;;
    *)
    echo "Usage: \$0 [-r] [-c]"
    exit 1
    ;;
  esac
done
EOS

print FILE <<'EOS';
set +e
# Set some paths and prime system to save environment variables
save () {
  (echo -n "$1=\""; eval "echo -n \"\$$1\""; echo '"') >> environment.sh
}
GC=
RC=
NC=
if tty -s < /dev/fd/1 2> /dev/null; then
  GC='\e[0;32m'
  RC='\e[0;31m'
  NC='\e[0m'
fi
log () {
  d=$(date)
  echo -e "${GC}[$d]${NC} $@"
}
fail () {
  d=$(date)
  echo -e "${RC}[$d]${NC} $@"
  exit 1
}
signaled () {
  fail Interrupted
}
trap signaled TERM QUIT INT
rm -f environment.sh; touch environment.sh

# To run tasks in parallel
run_bg () {
  semaphore -j $NUM_THREADS --id masurca_$$ -- "$@"
}
run_wait () {
  semaphore -j $NUM_THREADS --id masurca_$$ --wait
}
EOS
    ;

if(@prep_path) {
  print FILE "export PATH=\"", join(":", @prep_path), ":\$PATH\"\n";
} else {
  print FILE "export PATH=\"$RealBin:$RealBin/../CA/Linux-amd64/bin:\$PATH\"\n";
}
print FILE "save PATH\n";

if(@prep_ld) {
  print FILE "export LD_LIBRARY_PATH=\"", join(":", @prep_ld), ":\$LD_LIBRARY_PATH\"\n";
  print FILE "save LD_LIBRARY_PATH\n";
}
print FILE "NUM_THREADS=$config{NUM_THREADS}\n";
print FILE "save NUM_THREADS\n";

#override use linking mates if we have any long reads
$config{USE_LINKING_MATES}  = 1 if(not(@{$config{JUMP_INFO}}));
$config{USE_LINKING_MATES}  = 0 if(@{$config{OTHER_INFO}});
my $tmplist         = join(" ", @{$config{OTHER_INFO}});
$tmplist.=" moleculo_shr.frg " if(@{$config{MOLECULO_INFO}});
$list_frg_files    .= " ".$tmplist." ";

###renaming reads###

@pe_files        = rename_reads("pe", @{$config{PE_INFO}});
@sj_files        = rename_reads("sj", @{$config{JUMP_INFO}}) if(@{$config{JUMP_INFO}});
print FILE "run_wait\n";
$list_pe_files   = join(" ", @pe_files);
$list_jump_files = join(" ", @sj_files);

###done renaming reads###
print FILE "\n";

###compute minimum and average PE read length and gc content, and kmer size###
print FILE "head -q -n 40000  $list_pe_files | grep --text -v '^\+' | grep --text -v '^\@' > pe_data.tmp\n";
print FILE "PE_AVG_READ_LENGTH=`awk '{n+=length(\$1);m++;}END{print int(n/m)}' pe_data.tmp`\n";
print FILE "save PE_AVG_READ_LENGTH\n";
print FILE "echo \"Average PE read length \$PE_AVG_READ_LENGTH\"\n";

if(uc($config{KMER}) eq "AUTO"){
#here we have to estimate gc content and recompute kmer length for the graph
     &estimate_optimal_kmer($list_pe_files,"KMER");
     print FILE "save KMER\n";
     print FILE "echo \"choosing kmer size of \$KMER for the graph\"\n";
}else{
     print FILE "KMER=$config{KMER}\n";
}

if(@{$config{JUMP_INFO}} > 0){    
    &estimate_optimal_kmer($list_jump_files,"KMER_J");
    print FILE "save KMER_J\n";
}else{
   print FILE "KMER_J=\$KMER\n";
}
###done###

###Jellyfish###

&get_MIN_Q_CHAR($list_pe_files);

print FILE "JF_SIZE=`ls -l *.fastq | awk '{n+=\$5}END{s=int(n/50); if(s>$config{JF_SIZE})print s;else print \"$config{JF_SIZE}\";}'`\n";
print FILE "save JF_SIZE\n";
print FILE "perl -e '{if(int('\$JF_SIZE')>$config{JF_SIZE}){print \"WARNING: JF_SIZE set too low, increasing JF_SIZE to at least '\$JF_SIZE', this automatic increase may be not enough!\\n\"}}'\n"; 
if(not(-e "quorum_mer_db.jf") || $rerun_pe==1){
    print FILE "log Creating mer database for Quorum.\n";
    &count_kmers_for_quorum($list_pe_files, $config{NUM_THREADS}, 5);
    $rerun_pe=1;
    $rerun_sj=1;
}

###done Jellyfish###
print FILE "\n";
###error correct PE###

my $homo_polymer_flag = $config{DO_HOMOPOLYMER_TRIM} ? "--homo-trim $config{TRIM_PARAM}" : "";
my $mmap_flag = $config{NO_MMAP} ? "-M" : "";

if(not(-e "pe.cor.fa")||$rerun_pe==1){
  print FILE <<"EOS";
log Error correct PE.

quorum_error_correct_reads  -q \$((MIN_Q_CHAR + $config{RELIABLE_Q_PARAM})) --contaminant=$RealBin/../share/adapter.jf -m $config{KMER_COUNT_THRESHOLD} -s 1 -g 1 -a $config{KMER_RELIABLE_THRESHOLD} -t $config{NUM_THREADS} -w $WINDOW -e $MAX_ERR_PER_WINDOW $mmap_flag $homo_polymer_flag quorum_mer_db.jf $list_pe_files --no-discard -o pe.cor --verbose 1>quorum.err 2>&1 || {
  fail Error correction of PE reads failed. Check pe.cor.log.
}
EOS
    $rerun_pe=1;
}

###done error correct PE###
print FILE "\n";
###error correct JUMP###

if(@{$config{JUMP_INFO}} > 0){
    if(not(-e "sj.cor.fa")||$rerun_sj==1){
      print FILE <<"EOS";
log Error correct JUMP.

quorum_error_correct_reads -q \$((MIN_Q_CHAR + $config{RELIABLE_Q_PARAM})) --contaminant=$RealBin/../share/adapter.jf -m $config{KMER_COUNT_THRESHOLD} -s 1 -g 2 -a $config{KMER_RELIABLE_THRESHOLD} -t $config{NUM_THREADS} -w $WINDOW -e $MAX_ERR_PER_WINDOW $mmap_flag $homo_polymer_flag quorum_mer_db.jf $list_jump_files --no-discard -o sj.cor --verbose 1>quorum.err 2>&1 || {
  fail Error correction of JUMP reads failed. Check sj.cor.log.
}
EOS
      $rerun_sj=1;
    }
}

###done error correct JUMP###
print FILE "\n";
###estimate genome size###
my $k_u_arg="pe.cor.fa";
$k_u_arg.=" sj.cor.fa" if(@{$config{JUMP_INFO}});

print FILE "log Estimating genome size.\n";
if(not(-e "k_u_hash_0")||$rerun_pe==1||$rerun_sj==1){
    print FILE "jellyfish-2.0 count -m 31 -t $config{NUM_THREADS} -C -s \$JF_SIZE -o k_u_hash_0 $k_u_arg\n";
}

print FILE "ESTIMATED_GENOME_SIZE=`jellyfish-2.0 histo -t $config{NUM_THREADS} -h 1 k_u_hash_0 | tail -n 1 |awk '{print \$2}'`\n";
if($config{CA_PARAMETERS}=~ "cgwErrorRate=0.25" || $config{LIMIT_JUMP_COVERAGE} == 60) {print FILE "if [ \$ESTIMATED_GENOME_SIZE -ge 15000000 ]; then echo \"WARNING! CA_PARAMETERS = cgwErrorRate=0.25 and LIMIT_JUMP_COVERAGE = 60 in config file should only be used for bacterial genomes; set cgwErrorRate=0.15 and  LIMIT_JUMP_COVERAGE=300 for eukaryotes and plants!\";fi\n";}
print FILE "save ESTIMATED_GENOME_SIZE\n";
print FILE "echo \"Estimated genome size: \$ESTIMATED_GENOME_SIZE\"\n";

####done estimate genome size###
print FILE "\n";
###build k-unitigs###

if(not(-e "guillaumeKUnitigsAtLeast32bases_all.fasta")||$rerun_pe==1||$rerun_sj==1){
    print FILE "log Creating k-unitigs with k=\$KMER\n";
    print FILE "create_k_unitigs_large_k -c \$((\$KMER-1)) -t $config{NUM_THREADS} -m \$KMER -n \$ESTIMATED_GENOME_SIZE -l \$KMER -f 0.000001 $k_u_arg  | grep --text -v '^>' | perl -ane '{\$seq=\$F[0]; \$F[0]=~tr/ACTGactg/TGACtgac/;\$revseq=reverse(\$F[0]); \$h{(\$seq ge \$revseq)?\$seq:\$revseq}=1;}END{\$n=0;foreach \$k(keys \%h){print \">\",\$n++,\" length:\",length(\$k),\"\\n\$k\\n\"}}' > guillaumeKUnitigsAtLeast32bases_all.fasta\n";
    print FILE "if [[ \$KMER -eq \$KMER_J ]];then\n";
    print FILE "ln -s guillaumeKUnitigsAtLeast32bases_all.fasta guillaumeKUnitigsAtLeast32bases_all.jump.fasta\n";
    print FILE "else\n";
    print FILE "log Creating k-unitigs with k=\$KMER_J\n";
    print FILE "create_k_unitigs_large_k -c \$((\$KMER_J-1)) -t $config{NUM_THREADS} -m \$KMER_J -n \$ESTIMATED_GENOME_SIZE -l \$KMER_J -f 0.000001 $k_u_arg  | grep --text -v '^>' | perl -ane '{\$seq=\$F[0]; \$F[0]=~tr/ACTGactg/TGACtgac/;\$revseq=reverse(\$F[0]); \$h{(\$seq ge \$revseq)?\$seq:\$revseq}=1;}END{\$n=0;foreach \$k(keys \%h){print \">\",\$n++,\" length:\",length(\$k),\"\\n\$k\\n\"}}' > guillaumeKUnitigsAtLeast32bases_all.jump.fasta\n";
    print FILE "fi\n";
    $rerun_pe=1;
    $rerun_sj=1;
}

###done build k-unitigs###
print FILE "\n";
###super reads and filtering for jump###
if( not(-d "CA") || $rerun_pe || $rerun_sj ){
    if(@{$config{JUMP_INFO}} > 0){
        print FILE "log 'Filtering JUMP.'\n";
	&filter_jump(%config);
}
}
###done with super reads and filtering for jump###
    print FILE "\n";
##super reads for PE###

    print FILE "log 'Computing super reads from PE '\n";

#create super reads from PE    
    if($rerun_pe==1|| not(-e "work1")){
	print FILE "rm -rf work1\n";
	$rerun_pe=1;
    } 
    
    if(@{$config{PACBIO_INFO}}){
    print FILE "createSuperReadsForDirectory.perl -doSimpleMerge -l \$KMER -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.pe.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.fasta -t $config{NUM_THREADS} -mikedebug work1 pe.cor.fa 1> super1.err 2>&1\n";
    print FILE "$RealBin/mega_reads_assemble.sh -m work1 -p $config{PACBIO_INFO}[0] -a $RealBin/../CA8/Linux-amd64/bin -o \"$list_frg_files\"\n";
    close(FILE);
    chmod 0755, $assembly_script;
    exit(0);
    }else{    
    print FILE "createSuperReadsForDirectory.perl -l \$KMER -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.pe.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.fasta -t $config{NUM_THREADS} -mikedebug work1 pe.cor.fa 1> super1.err 2>&1\n";

#check if the super reads pipeline finished successfully
    print FILE "if [[ ! -e work1/superReads.success ]];then\n";
    print FILE "fail Super reads failed, check super1.err and files in ./work1/\n";
    print FILE "fi\n";

    if($config{SOAP_ASSEMBLY}){
    my $cmdline="splitFileByPrefix.pl";
    foreach my $v (@{$config{JUMP_INFO}}) {
            my @f = split(" ", $v);
	    $cmdline.=" $f[0]";
     }
    print FILE "$cmdline < sj.cor.clean2.fa\n";
    print FILE "log 'SOAPdenovo'\n";
    print FILE "mkdir -p SOAP_assembly\n";
    print FILE "cd SOAP_assembly\n";
    print FILE "if [ \$KMER -le 63 ];then\n";
    print FILE "SOAPdenovo-63mer all -u -w -p $config{NUM_THREADS} -D 0 -d 0 -K \$KMER -k 33 -R -o asm -s ../soap_config 1>../SOAPdenovo.err 2>\&1\n";
    print FILE "else\n";
    print FILE "SOAPdenovo-127mer all -u -w -p $config{NUM_THREADS} -D 0 -d 0 -K \$KMER -k 33 -R -o asm -s ../soap_config 1>../SOAPdenovo.err 2>\&1\n";
    print FILE "fi\n";
    print FILE "cd ..\n";
    if($config{CLOSE_GAPS}){

    print FILE "log 'Gap closing'\n";
    my $reads_argument= join(" ", map { "--reads-file '$_'" } (@pe_files, @sj_files));
    print FILE "if [[ -e \"SOAP_assembly/asm.scafSeq\" ]];then\n";
    print FILE "closeGapsInScaffFastaFile.perl  --max-reads-in-memory 1000000000 -s $config{JF_SIZE} --scaffold-fasta-file  SOAP_assembly/asm.scafSeq $reads_argument --output-directory SOAP_gapclose --min-kmer-len 19 --max-kmer-len \$((\$PE_AVG_READ_LENGTH-5)) --num-threads $config{NUM_THREADS} --contig-length-for-joining \$((\$PE_AVG_READ_LENGTH-1)) --contig-length-for-fishing 200 --reduce-read-set-kmer-size 25 1>gapClose.err 2>&1\n";
    print FILE "if [[ -e \"SOAP_gapclose/genome.ctg.fasta\" ]];then\n";
    print FILE "echo \"Gap close success. Output sequence is in SOAP_gapclose/genome.\{ctg,scf\}.fasta\"\n";
    print FILE "else\n";
    print FILE "fail Gap close failed, you can still use pre-gap close scaffold file asm.scafSeq. Check gapClose.err for problems.\n";
    print FILE "fi\n";
    print FILE "else\n";
    print FILE "fail SOAPdenovo failed, Check SOAPdenovo.err for problems.\n";
    print FILE "fi\n";
    }
    close(FILE);
    chmod 0755, $assembly_script;
    print "done.\nexecute $assembly_script to run assembly with SOAPdenovo\n";
    exit(0);
    }

if($config{USE_LINKING_MATES} == 1){
#now we extract those PE mates that did not end up in the same super read -- we call them linking mates, they will be useful for scaffolding
	if(not(-e "pe.linking.fa")||$rerun_pe==1){
	    print FILE "extractreads.pl <( awk 'BEGIN{last_readnumber=-1;last_super_read=\"\"}{readnumber=int(substr(\$1,3));if(readnumber%2>0){readnumber--}super_read=\$2;if(readnumber==last_readnumber){if(super_read!=last_super_read){print read;print \$1;}}else{read=\$1;last_super_read=\$2}last_readnumber=readnumber}' work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt )  pe.cor.fa 1 > pe.linking.fa\n";
	    $rerun_pe=1;
	}
    print FILE "NUM_LINKING_MATES=`wc -l pe.linking.fa | perl -ane '{print int(\$F[0]/2)}'`\n";
    if(@{$config{JUMP_INFO}}){
    print FILE "MAX_LINKING_MATES=`perl -e '{\$g=int('\$ESTIMATED_GENOME_SIZE'/25);\$g=250000000 if(\$g>250000000);print \$g}'`\n";
    }else{
    print FILE "MAX_LINKING_MATES=`perl -e '{\$g=int('\$ESTIMATED_GENOME_SIZE');\$g=250000000 if(\$g>250000000);print \$g}'`\n";
    }
    &create_pe_linking_mates(%config);

#create frg file for super reads
    if(not(-e "superReadSequences_shr.frg")||$rerun_pe==1){
	print FILE "create_sr_frg.pl < work1/superReadSequences.fasta 2>/dev/null | fasta2frg.pl super >  superReadSequences_shr.frg\n";
    }
###done with super reads for PE###
    print FILE "\n";
    }
    }

if($config{STOP_AFTER_SR}) {
  print FILE "log 'Super reads done'\n";
  close(FILE);
  chmod 0755, $assembly_script;
  print "done.\nexecute $assembly_script to create the super reads\n";
  exit(0);
}

if(@{$config{MOLECULO_INFO}} && not(-e "moleculo_shr.frg")){
         my $i=0;
         foreach my $f(@{$config{MOLECULO_INFO}}){
         print FILE "perl -e '\$n=0;while(\$line=<>){print \">moleculo$i.\$n\\n\";\$n++;\$line=<>;print \$line;\$line=<>;\$line=<>;}' $f  | create_sr_frg.pl 2>/dev/null | fasta2frg_m.pl moleculo$i >>  moleculo_shr.frg\n";
         }
}

###Celera Assembler###
if(not(-e "CA/9-terminator/genome.qc")|| $rerun_pe || $rerun_sj){
    print FILE "\nlog 'Celera Assembler'\n";
    if($rerun_sj==1||$rerun_pe==1){
	print FILE "rm -rf CA\n";
    }
    &runCA($list_frg_files, $tmplist, %config);
}

#here we close gaps in scaffolds:  we use create_k_unitigs allowing to continue on count 1 sequence and then generate fake reads from the 
#end sequences of contigs that are next to each other in scaffolds, and then use super reads software to close the gaps for k=17...31
if($config{CLOSE_GAPS}){

    print FILE "log 'Gap closing'\n";
    my $reads_argument= join(" ", map { "--reads-file '$_'" } (@pe_files, @sj_files));

    print FILE "closeGapsLocally.perl --max-reads-in-memory 1000000000 -s $config{JF_SIZE} --Celera-terminator-directory CA/9-terminator $reads_argument --output-directory CA/10-gapclose --min-kmer-len 17 --max-kmer-len \$((\$PE_AVG_READ_LENGTH-5)) --num-threads $config{NUM_THREADS} --contig-length-for-joining \$((\$PE_AVG_READ_LENGTH-1)) --contig-length-for-fishing 200 --reduce-read-set-kmer-size 21 1>gapClose.err 2>&1\n";
    print FILE "if [[ -e \"CA/10-gapclose/genome.ctg.fasta\" ]];then\n";
    print FILE "echo \"Gap close success. Output sequence is in CA/10-gapclose/genome.\{ctg,scf\}.fasta\"\n";
    print FILE "else\n";
    print FILE "fail Gap close failed, you can still use pre-gap close files under CA/9-terminator/. Check gapClose.err for problems.\n";
    print FILE "fi\n";
}

###Done !!!! Hoorayyyy!!! :)###
print FILE "log 'All done'\n";

close(FILE);
chmod 0755, $assembly_script;
print "done.\nexecute $assembly_script to run the assembly\n";


