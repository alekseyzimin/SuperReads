#!/usr/bin/env perl
# SuperRead pipeline
# Copyright (C) 2012  Genome group at University of Maryland.
# 
# This program is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

#This script reads the the config file and runs the full super reads pipeline
#config file format:
#
#DATA
#PE= id mean stdev fastq_forward fastq_reverse
#JUMP= id mean stdev fastq_forward fastq_reverse 
#OTHER=frag1.frg
#END
#
#PARAMETERS
#KMER_COUNT_THRESHOLD=1
#NUM_THREADS=24
#JF_SIZE=2000000000
#EXTEND_JUMP_READS=0
#END
#

use strict;
use warnings;
use Env qw(@PATH @LD_LIBRARY_PATH);
use File::Spec;
use FindBin qw($RealBin);
use Getopt::Long;

#global variables
my (@pe_files, @sj_files);
my ($list_pe_files, $list_jump_files);
my $list_frg_files = "";
my $rerun_pe          = 0;
my $rerun_sj          = 0;
my $KMER                    = "auto";
my $CA_PARAMETERS           = "";
my $WINDOW                  = 10;
my $MAX_ERR_PER_WINDOW      = 3;
my $KMER_COUNT_THRESHOLD    = 1;
my $KMER_RELIABLE_THRESHOLD = 3;
my $TRIM_PARAM              = 3;
my $RELIABLE_Q_PARAM	    = 35;
my $NUM_THREADS             = 2;
my $EXTEND_JUMP_READS       = 1;
my $JF_SIZE                 = 100000000;
my $in_data                 = 0;
my $in_parameters           = 0;
my @pe_info_array           = ();
my @jump_info_array         = ();
my @other_info_array        = ();
my %used_library_ids;
my $LIMIT_JUMP_COVERAGE     = 1000;
my $USE_LINKING_MATES       = 0;
my $DO_HOMOPOLYMER_TRIM     = 0;
my $CLOSE_GAPS              = 1;
my $NO_MMAP                 = 0;

my $assembly_script = "assemble.sh";
my $generate_default;
my $skip_path_checking;
my @prep_path;
my @prep_ld;
my $help;

my $usage = "USAGE: $0 <config_file>";
my $help_str = <<"EOS" ;
Create the assembly script from a MaSuRCA configuration file. An
sample configuration file can be generated with the -g switch. The
assembly script will run the assembly proper.

Options:
 -o, --output              Assembly script ($assembly_script)
 -g, --generate            Generate example configuration file
 -p, --path                Prepend to PATH in assembly script
 -l, --ld-library-path     Prepend to LD_LIBRARY_PATH in assembly script
     --skip-path-checking  Skip checking availability of other executables
 -h, --help                This message
EOS
    ;


# Like die, but don't print backtrace like information
my $config_file;
sub fail {
  print(STDERR "Error");
  if(defined($config_file) &&  defined($_[1])) {
    print(STDERR " line $_[1] of configuration file '$config_file':\n");
  } else {
    print(STDERR ": ");
  }
  chomp($_[0]);
  print(STDERR $_[0], "\n");
  exit(1);
}

sub rename_reads {
  my ($type, @read_info) = @_;
  my @res;
  my $out = "meanAndStdevByPrefix.$type.txt";
  my $do_wait = 0;

  print FILE "log 'Processing $type library reads'\n";
  print FILE "rm -rf $out\n";
  foreach my $v (@read_info){
    my ($name, $mean, $stdev, $fr, $rr) = split(" ", $v);
    my $renamed = "$name.renamed.fastq";
    ($mean, $stdev) = (500, 100) if($type eq "sj");
    push(@res, $renamed);
    print FILE "echo '$name $mean $stdev' >> $out\n";
    next if(-e $renamed);
    $do_wait = 1;
    $rerun_pe = 1;
    $rerun_sj = 1;
    print( FILE "run_bg rename_filter_fastq '$name' <(exec expand_fastq '$fr' | awk '{if(length(\$0>200)) print substr(\$0,1,200); else print \$0;}') ",
           defined($rr) ? "<(exec expand_fastq '$rr' | awk '{if(length(\$0>200)) print substr(\$0,1,200); else print \$0;}' )" : "''",
           " > '$renamed'\n");
  }
  return @res;
}

sub estimate_optimal_kmer{
  my ($filelist, $name) = @_;
  my $max_kmer=127;
  if($name eq "KMER_J"){
  print FILE "$name=31\n";
  }else{
  print FILE "$name=`for f in $filelist;do head -n 80000 \$f |tail -n 40000;done | perl -e 'while(\$line=<STDIN>){\$line=<STDIN>;chomp(\$line);push(\@lines,\$line);\$line=<STDIN>;\$line=<STDIN>}\$min_len=100000;\$base_count=0;foreach \$l(\@lines){\$base_count+=length(\$l);if(length(\$l)<\$min_len){\$min_len=length(\$l)} \@f=split(\"\",\$l);foreach \$base(\@f){if(uc(\$base) eq \"G\" || uc(\$base) eq \"C\"){\$gc_count++}}} \$gc_ratio=\$gc_count/\$base_count;\$kmer=0;if(\$gc_ratio<0.5){\$kmer=int(\$min_len*.7);}elsif(\$gc_ratio>=0.5 && \$gc_ratio<0.6){\$kmer=int(\$min_len*.5);}else{\$kmer=int(\$min_len*.33);} \$kmer=31 if(\$kmer<31); \$kmer=$max_kmer if(\$kmer>$max_kmer); print \$kmer'`\n";
}
}

sub get_MIN_Q_CHAR{
  my $filelist=$_[0];
  print FILE "MIN_Q_CHAR=`cat $filelist |head -n 50000 | awk 'BEGIN{flag=0}{if(\$0 ~ /^\\+/){flag=1}else if(flag==1){print \$0;flag=0}}'  | perl -ne 'BEGIN{\$q0_char=\"\@\";}{chomp;\@f=split \"\";foreach \$v(\@f){if(ord(\$v)<ord(\$q0_char)){\$q0_char=\$v;}}}END{\$ans=ord(\$q0_char);if(\$ans<65){print \"33\\n\"}else{print \"64\\n\"}}'`\n";
  print FILE "save MIN_Q_CHAR\n";
  print FILE "echo MIN_Q_CHAR: \$MIN_Q_CHAR\n";
}

sub count_kmers_for_quorum {
  my ($filelist, $NUM_THREADS, $thresh) = @_;
  print FILE <<"EOS";
quorum_create_database -t $NUM_THREADS -s \$JF_SIZE -b 7 -m 24 -q \$((MIN_Q_CHAR + $thresh)) -o quorum_mer_db.jf $filelist
if [ $? != 0 ]; then
  echo "Increase JF_SIZE in config file, the recommendation is to set this to genome_size*coverage/2"
  exit
fi
EOS
}

sub check_exec {
  for my $e (@_) {
    system("$e --help >/dev/null 2>&1") == 0 or fail "$e not found or failed to run";
    print "$e OK\n";
  }
}

#parsing config file
GetOptions("o|output=s"          => \$assembly_script,
           "g|generate"          => \$generate_default,
           "p|path=s"            => \@prep_path,
           "l|ld-library-path=s" => \@prep_ld,
           "skip-checking"       => \$skip_path_checking,
           "h|help"              => \$help) or fail $usage;

if($help) {
  print "$help_str";
  exit(0);
}
fail $usage if @ARGV != 1;
$config_file = $ARGV[0];

if($generate_default) {
  fail "Refusing to overwrite existing configuration file '$config_file'" if(-e $config_file);
  open(FILE, ">", $config_file) or fail "Error opening configuration file '$config_file': $!";
  print FILE <<'EOS';
# example configuration file 

# DATA is specified as type {PE,JUMP,OTHER} and 5 fields:
# 1)two_letter_prefix 2)mean 3)stdev 4)fastq(.gz)_fwd_reads
# 5)fastq(.gz)_rev_reads. The PE reads are always assumed to be
# innies, i.e. --->.<---, and JUMP are assumed to be outties
# <---.--->. If there are any jump libraries that are innies, such as
# longjump, specify them as JUMP and specify NEGATIVE mean. Reverse reads
# are optional for PE libraries and mandatory for JUMP libraries. Any
# OTHER sequence data (454, Sanger, Ion torrent, etc) must be first
# converted into Celera Assembler compatible .frg files (see
# http://wgs-assembler.sourceforge.com)
DATA
PE= pe 180 20  /FULL_PATH/frag_1.fastq  /FULL_PATH/frag_2.fastq
JUMP= sh 3600 200  /FULL_PATH/short_1.fastq  /FULL_PATH/short_2.fastq
OTHER=/FULL_PATH/file.frg
END

PARAMETERS
#this is k-mer size for deBruijn graph values between 25 and 101 are supported, auto will compute the optimal size based on the read data and GC content
GRAPH_KMER_SIZE=auto
#set this to 1 for Illumina-only assemblies and to 0 if you have 1x or more long (Sanger, 454) reads, you can also set this to 0 for large data sets with high jumping clone coverage, e.g. >50x
USE_LINKING_MATES=0
#this parameter is useful if you have too many jumping library mates. Typically set it to 60 for bacteria and something large (300) for the other organisms 
LIMIT_JUMP_COVERAGE = 60
#these are the additional parameters to Celera Assembler.  do not worry about performance, number or processors or batch sizes -- these are computed automatically. 
#set cgwErrorRate=0.25 for bacteria and 0.1<=cgwErrorRate<=0.15 for other organisms.
CA_PARAMETERS = cgwErrorRate=0.15 ovlMemory=4GB
#minimum count k-mers used in error correction 1 means all k-mers are used.  one can increase to 2 if coverage >100
KMER_COUNT_THRESHOLD = 1
#auto-detected number of cpus to use
NUM_THREADS= $NUM_THREADS
#this is mandatory jellyfish hash size -- a safe value is estimated_genome_size*estimated_coverage
JF_SIZE=100000000
#this specifies if we do (1) or do not (0) want to trim long runs of homopolymers (e.g. GGGGGGGG) from 3' read ends, use it for high GC genomes
DO_HOMOPOLYMER_TRIM=0
END
EOS
  close(FILE);
  exit(0);
}

# Match a line of the form "KEY = VALUE". Returns undef if it does not match
sub read_param {
  my ($line) = @_;
  fail("Can't parse line '$line'", $.) unless $line =~ /^\s*(\w+)\s*=\s*(.*)$/;
  my ($k, $v) = ($1, $2);
  chomp($v);
  return ($k, $v);
}

open(FILE, "<", $config_file) or fail "Can't open config file '$config_file': $!";
while(my $line=<FILE>){
    chomp($line);
    next if($line =~ /^\s*(#|$)/);
    if($line =~ /^DATA\s*$/){
      fail("error in config file: mixed PARAMETERS and DATA", $.) if $in_parameters;
      fail("duplicate DATA header", $.) if $in_data;
      $in_data = 1;
      next;
    } elsif($line =~ /^PARAMETERS\s*$/){
      fail("error in config file: mixed PARAMETERS and DATA", $.) if $in_data;
      fail("duplicate PARAMETERS header", $.) if $in_parameters;
      $in_parameters=1;
      next;
    } elsif($line =~ /^PATHS\s*$/) {
      warn("PATHS section is obsolete. You should remove it from your configuration file. Skipping to next section...");
      while(<FILE> !~ /^END\s*/) { }
      next;
    } elsif($line =~ /^END\s*$/) {
      fail("Unexpected 'END' keyword. Not in PARAMETERS or DATA section", $.) if(!($in_parameters || $in_data));
      $in_data = $in_parameters = 0;
      next;
    }

    my ($key, $param) = read_param($line);
    
    if($in_parameters==1){
        if($key eq "EXTEND_JUMP_READS"){
            fail("bad value for EXTEND_JUMP_READS, enter 0 or 1", $.) unless($param =~ /^[01]$/);
	    $EXTEND_JUMP_READS=int($param);
	} elsif($key eq "DO_HOMOPOLYMER_TRIM"){
            fail("bad value for DO_HOMOPOLYMER_TRIM, enter 0 or 1", $.) unless($param =~ /^[01]$/);
            $DO_HOMOPOLYMER_TRIM=int($param);
        } elsif($key eq "TRIM_PARAM") {
            fail("bad value for TRIM_PARAM, it should be a positive integer", $.) unless $param =~ /^\d*$/;
            $TRIM_PARAM = length($param) > 0 ? int($param) : 2;
        } elsif($key eq "RELIABLE_Q_PARAM") {
            fail("bad value for RELIABLE_Q_PARAM, it should be a positive integer", $.) unless $param =~ /^\d*$/;
            $RELIABLE_Q_PARAM = length($param) > 0 ? int($param) : 35;
	} elsif($key eq "CLOSE_GAPS"){
            fail("bad value for CLOSE_GAPS, enter 0 or 1", $.) unless($param =~ /^[01]$/);
            $CLOSE_GAPS=int($param);
          } elsif($key eq "CA_PARAMETERS"){
	    $CA_PARAMETERS=$param;
	    fail("bad value for CA_PARAMETERS", $.) if($CA_PARAMETERS eq "");
	} elsif($key eq "LIMIT_JUMP_COVERAGE"){
            $LIMIT_JUMP_COVERAGE=int($param);
            fail("bad value for LIMIT_JUMP_COVERAGE, enter a number > 1", $.) if($LIMIT_JUMP_COVERAGE<=1);
        } elsif($key eq "GRAPH_KMER_SIZE"){
            $KMER=$param;
            fail("bad value for GRAPH_KMER_SIZE, enter auto or number >= 15 and <= 151", $.) if(not($KMER eq "auto") && ($KMER<15 || $KMER>151));
        } elsif($key eq "USE_LINKING_MATES"){
            fail("bad value for USE_LINKING_MATES, enter 0 or 1", $.) unless $param =~ /^[01]$/;
            $USE_LINKING_MATES=int($param);
          } elsif($key eq "KMER_COUNT_THRESHOLD"){
	    $KMER_COUNT_THRESHOLD=int($param);
	    $KMER_RELIABLE_THRESHOLD=3*$KMER_COUNT_THRESHOLD;
	    fail("bad value for KMER_COUNT_THRESHOLD. Enter a number >= 1", $.) if($KMER_COUNT_THRESHOLD<1);
	} elsif($key eq "NUM_THREADS"){
	    $NUM_THREADS=int($param);
	    fail("bad value for NUM_THREADS. Enter a number >= 1", $.) if($NUM_THREADS<1);
	} elsif($key eq "JF_SIZE"){
	    $JF_SIZE=int($param);
	    fail("bad value for JF_SIZE, enter a number >= 100000", $.) if($JF_SIZE<100000);
        } elsif($key eq "NO_MMAP"){
            fail("bad value for NO_MMAP, enter 0 or 1", $.) unless($param =~ /^[01]$/);
            $NO_MMAP=int($param);
	} else {
            fail "Could not parse line '$line'";
        }
    }

    if($in_data==1){
      if($key eq "PE"){
	    my @f=split(" ", $param);
	    fail("improper id for PE library '$f[0]'. It should be two character long (like 'p0')", $.) if(not(length($f[0])==2));
	    fail("duplicate id for PE library '$f[0]'", $.) if(defined($used_library_ids{$f[0]}));
	    my $pe_info_line ="$f[0] ";
	    $used_library_ids{$f[0]}=1;
	    fail("improper mean '$f[1]' for PE library '$f[0]'. It must be a positive number", $.) unless(int($f[1])>0);
	    $pe_info_line.="$f[1] ";
	    fail("improper stdev '$f[2]' for PE library '$f[0]'. It must be a positive number", $.) unless(int($f[2])>0);
	    $pe_info_line.="$f[2] ";
            open(my $io, "<", $f[3]) or fail("invalid forward file for PE library '$f[0]': '$f[3]' $!", $.);
            close($io);
	    $pe_info_line.="$f[3] ";
	    if(defined($f[4])){
              open($io, "<", $f[4]) or fail("invalid reverse file for PE library '$f[0]': '$f[4]' $!", $.);
              close($io);
              $pe_info_line.="$f[4] ";
	    }
	    else{
		$pe_info_line.="$f[3] ";
	    }
	    push(@pe_info_array,$pe_info_line);
	} elsif($key eq "JUMP"){
	    my @f=split(" ", $param);
	    fail("improper id for JUMP library '$f[0]'. It should be two character long (like 'j1')", $.) if(not(length($f[0])==2));
	    fail("duplicate id for JUMP library '$f[0]'", $.) if(defined($used_library_ids{$f[0]}));
	    my $jump_info_line="$f[0] ";
	    $used_library_ids{$f[0]}=1;
	    fail("improper mean '$f[1]' for JUMP library '$f[0]'. It must be a number strictly greater or less than zero", $.) if(int($f[1])==0);
	    $jump_info_line.="$f[1] ";
	    fail("improper stdev '$f[2]' for JUMP library '$f[0]'. It must be a positive number", $.) unless(int($f[2])>0);
	    $jump_info_line.="$f[2] ";
            open(my $io, "<", $f[3]) or fail("invalid forward file for JUMP library '$f[0]': '$f[3]' $!", $.);
            close($io);
	    $jump_info_line.="$f[3] ";
	    open($io, "<", $f[4]) or fail("invalid reverse file for JUMP library '$f[0]': '$f[4]' $!", $.);
            close($io);
	    $jump_info_line.="$f[4] ";
	    push(@jump_info_array,$jump_info_line);
	}
	elsif($key eq "OTHER"){
	    fail("incorrect frg file name '$param'. It must end in '.frg'", $.) unless($param =~/\.frg$/);
            open(my $io, "<", $param) or fail("invalid frg file for OTHER: '$param' $!", $.);
            close($io);
            push(@other_info_array,$param);
	} else {
            fail "Could not parse line '$line'";
        }
    }
}
fail("no read data files specified") if(@pe_info_array + @jump_info_array + @other_info_array == 0);

if(@prep_path) {
  unshift(@PATH, @prep_path);
} else {
  unshift(@PATH, $RealBin, $RealBin . "/../CA/Linux-amd64/bin");
}
unshift(@LD_LIBRARY_PATH, @prep_ld) if @prep_ld;

unless($skip_path_checking) {
  print "Verifying PATHS...\n";
  &check_exec("jellyfish-2.0", "runCA", "createSuperReadsForDirectory.perl");
}

fail ("no PE data specified") if(@pe_info_array == 0);

print("creating script file for the actions...");

my $config_abs_path = File::Spec->rel2abs($config_file);
my $cmd_abs_path = File::Spec->rel2abs(__FILE__);

open(FILE,">", $assembly_script) or fail "Can't open output file '$assembly_script': $!";
print FILE <<"EOS";
#!/bin/bash

# $assembly_script generated by masurca
CONFIG_PATH="$config_abs_path"
CMD_PATH="$cmd_abs_path"

# Test that we support <() redirection
(eval "cat <(echo test) >/dev/null" 2>/dev/null) || {
  echo >&2 "ERROR: The shell used is missing important features."
  echo >&2 "       Run the assembly script directly as './\$0'"
  exit 1
}

# Parse command line switches
while getopts ":rc" o; do
  case "\${o}" in
    c)
    echo "configuration file is '\$CONFIG_PATH'"
    exit 0
    ;;
    r)
    echo "Rerunning configuration"
    exec perl "\$CMD_PATH" "\$CONFIG_PATH"
    echo "Failed to rerun configuration"
    exit 1
    ;;
    *)
    echo "Usage: \$0 [-r] [-c]"
    exit 1
    ;;
  esac
done
EOS

print FILE <<'EOS';
set +e
# Set some paths and prime system to save environment variables
save () {
  (echo -n "$1=\""; eval "echo -n \"\$$1\""; echo '"') >> environment.sh
}
GC=
NC=
if tty -s < /dev/fd/1 2> /dev/null; then
  GC='\e[0;32m'
  NC='\e[0m'
fi
log () {
  d=$(date)
  echo -e "${GC}[$d]${NC} $@"
}

rm -f environment.sh; touch environment.sh

# To run tasks in parallel
run_bg () {
  semaphore -j $NUM_THREADS --id masurca_$$ -- "$@"
}
run_wait () {
  semaphore -j $NUM_THREADS --id masurca_$$ --wait
}
EOS
    ;

if(@prep_path) {
  print FILE "export PATH=\"", join(":", @prep_path), ":\$PATH\"\n";
} else {
  print FILE "export PATH=\"$RealBin:$RealBin/../CA/Linux-amd64/bin:\$PATH\"\n";
}
print FILE "save PATH\n";

if(@prep_ld) {
  print FILE "export LD_LIBRARY_PATH=\"", join(":", @prep_ld), ":\$LD_LIBRARY_PATH\"\n";
  print FILE "save LD_LIBRARY_PATH\n";
}
print FILE "NUM_THREADS=$NUM_THREADS\n";
print FILE "save NUM_THREADS\n";

#override use linking mates if we have any long reads
$USE_LINKING_MATES  = 0 if(@other_info_array);
my $tmplist         = join(" ", @other_info_array);
$list_frg_files    .= " ".$tmplist." ";

###renaming reads###

@pe_files        = rename_reads("pe", @pe_info_array);
@sj_files        = rename_reads("sj", @jump_info_array) if(@jump_info_array);
print FILE "run_wait\n";
$list_pe_files   = join(" ", @pe_files);
$list_jump_files = join(" ", @sj_files);

###done renaming reads###
print FILE "\n";

###compute minimum and average PE read length and gc content, and kmer size###
print FILE "head -q -n 2  $list_pe_files | grep --text -v '^\@' > pe_data.tmp\n";
print FILE "PE_AVG_READ_LENGTH=`awk '{n+=length(\$1);m++;}END{print int(n/m)}' pe_data.tmp`\n";
print FILE "save PE_AVG_READ_LENGTH\n";
print FILE "echo \"Average PE read length \$PE_AVG_READ_LENGTH\"\n";

if(uc($KMER) eq "AUTO"){
#here we have to estimate gc content and recompute kmer length for the graph
     &estimate_optimal_kmer($list_pe_files,"KMER");
     print FILE "save KMER\n";
     print FILE "echo \"choosing kmer size of \$KMER for the graph\"\n";
}else{
     print FILE "KMER=$KMER\n";
}

if(@jump_info_array > 0){    
    &estimate_optimal_kmer($list_jump_files,"KMER_J");
    print FILE "save KMER_J\n";
}else{
   print FILE "KMER_J=\$KMER\n";
}
###done###

###Jellyfish###

&get_MIN_Q_CHAR($list_pe_files);

print FILE "JF_SIZE=`ls -l *.fastq | awk '{n+=\$5}END{s=int(n/50); if(s>$JF_SIZE)print s;else print \"$JF_SIZE\";}'`\n";
print FILE "save JF_SIZE\n";
print FILE "perl -e '{if(int('\$JF_SIZE')>$JF_SIZE){print \"WARNING: JF_SIZE set too low, increasing JF_SIZE to at least '\$JF_SIZE', this automatic increase may be not enough!\\n\"}}'\n"; 
if(not(-e "quorum_mer_db.jf") || $rerun_pe==1){
    print FILE "log Creating mer database for Quorum.\n";
    &count_kmers_for_quorum($list_pe_files, $NUM_THREADS, 5);
    $rerun_pe=1;
    $rerun_sj=1;
}

###done Jellyfish###
print FILE "\n";
###error correct PE###

my $homo_polymer_flag = $DO_HOMOPOLYMER_TRIM ? "--homo-trim $TRIM_PARAM" : "";
my $mmap_flag = $NO_MMAP ? "-M" : "";

if(not(-e "pe.cor.fa")||$rerun_pe==1){
  print FILE <<"EOS";
log Error correct PE.

quorum_error_correct_reads  -q \$((MIN_Q_CHAR + $RELIABLE_Q_PARAM)) --contaminant=$RealBin/../share/adapter.jf -m $KMER_COUNT_THRESHOLD -s 1 -g 1 -a $KMER_RELIABLE_THRESHOLD -t $NUM_THREADS -w $WINDOW -e $MAX_ERR_PER_WINDOW $mmap_flag $homo_polymer_flag quorum_mer_db.jf $list_pe_files --no-discard -o pe.cor --verbose 1>quorum.err 2>&1 || {
  echo >&2 Error correction of PE reads failed. Check pe.cor.log.
  exit 1
}
EOS
    $rerun_pe=1;
}

###done error correct PE###
print FILE "\n";
###error correct JUMP###

if(@jump_info_array > 0){
    if(not(-e "sj.cor.fa")||$rerun_sj==1){
      print FILE <<"EOS";
log Error correct JUMP.

quorum_error_correct_reads -q \$((MIN_Q_CHAR + $RELIABLE_Q_PARAM)) --contaminant=$RealBin/../share/adapter.jf -m $KMER_COUNT_THRESHOLD -s 1 -g 2 -a $KMER_RELIABLE_THRESHOLD -t $NUM_THREADS -w $WINDOW -e $MAX_ERR_PER_WINDOW $mmap_flag $homo_polymer_flag quorum_mer_db.jf $list_jump_files --no-discard -o sj.cor --verbose 1>quorum.err 2>&1 || {
  echo >&2 Error correction of JUMP reads failed. Check sj.cor.log.
  exit 1
}
EOS
      $rerun_sj=1;
    }
}

###done error correct JUMP###
print FILE "\n";
###estimate genome size###
my $k_u_arg="pe.cor.fa";
$k_u_arg.=" sj.cor.fa" if(@jump_info_array);

print FILE "log Estimating genome size.\n";
if(not(-e "k_u_hash_0")||$rerun_pe==1||$rerun_sj==1){
    print FILE "jellyfish-2.0 count -m 31 -t $NUM_THREADS -C -s \$JF_SIZE -o k_u_hash_0 $k_u_arg\n";
}

print FILE "ESTIMATED_GENOME_SIZE=`jellyfish-2.0 histo -t $NUM_THREADS -h 1 k_u_hash_0 | tail -n 1 |awk '{print \$2}'`\n";
if($CA_PARAMETERS =~ "cgwErrorRate=0.25" || $LIMIT_JUMP_COVERAGE==60) {print FILE "if [ \$ESTIMATED_GENOME_SIZE -ge 15000000 ]; then echo \"WARNING! CA_PARAMETERS = cgwErrorRate=0.25 and LIMIT_JUMP_COVERAGE = 60 in config file should only be used for bacterial genomes; set cgwErrorRate=0.15 and  LIMIT_JUMP_COVERAGE=300 for eukaryotes and plants!\";fi\n";}
print FILE "save ESTIMATED_GENOME_SIZE\n";
print FILE "echo \"Estimated genome size: \$ESTIMATED_GENOME_SIZE\"\n";

####done estimate genome size###
print FILE "\n";
###build k-unitigs###

if(not(-e "guillaumeKUnitigsAtLeast32bases_all.fasta")||$rerun_pe==1||$rerun_sj==1){
    print FILE "log Creating k-unitigs with k=\$KMER\n";
    print FILE "create_k_unitigs_large_k -c \$((\$KMER-1)) -t $NUM_THREADS -m \$KMER -n \$ESTIMATED_GENOME_SIZE -l \$KMER -f 0.000001 $k_u_arg  | grep --text -v '^>' | perl -ane '{\$seq=\$F[0]; \$F[0]=~tr/ACTGacgt/TGACtgac/;\$revseq=reverse(\$F[0]); \$h{(\$seq ge \$revseq)?\$seq:\$revseq}=1;}END{\$n=0;foreach \$k(keys \%h){print \">\",\$n++,\" length:\",length(\$k),\"\\n\$k\\n\"}}' > guillaumeKUnitigsAtLeast32bases_all.fasta\n";
    print FILE "if [[ \$KMER -eq \$KMER_J ]];then\n";
    print FILE "ln -s guillaumeKUnitigsAtLeast32bases_all.fasta guillaumeKUnitigsAtLeast32bases_all.jump.fasta\n";
    print FILE "else\n";
    print FILE "log Creating k-unitigs with k=\$KMER_J\n";
    print FILE "create_k_unitigs_large_k -c \$((\$KMER_J-1)) -t $NUM_THREADS -m \$KMER_J -n \$ESTIMATED_GENOME_SIZE -l \$KMER_J -f 0.000001 $k_u_arg  | grep --text -v '^>' | perl -ane '{\$seq=\$F[0]; \$F[0]=~tr/ACTGacgt/TGACtgac/;\$revseq=reverse(\$F[0]); \$h{(\$seq ge \$revseq)?\$seq:\$revseq}=1;}END{\$n=0;foreach \$k(keys \%h){print \">\",\$n++,\" length:\",length(\$k),\"\\n\$k\\n\"}}' > guillaumeKUnitigsAtLeast32bases_all.jump.fasta\n";
    print FILE "fi\n";
    $rerun_pe=1;
    $rerun_sj=1;
}


###done build k-unitigs###
print FILE "\n";
###super reads and filtering for jump###

if( not(-d "CA") || $rerun_pe || $rerun_sj ){
    if(@jump_info_array > 0){
        print FILE "log 'Filtering JUMP.'\n";

#creating super reads for filtering
	if($rerun_pe==1||$rerun_sj==1||not(-e "work2")){
	    print FILE "rm -rf work2\n";
	    $rerun_sj=1;
	}
	print FILE "createSuperReadsForDirectory.perl  -maxnodes 2000 -minreadsinsuperread 1 -l \$KMER_J -join-aggressive 1 -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.sj.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.jump.fasta -t $NUM_THREADS -mikedebug work2 sj.cor.fa 1> super2.err 2>&1\n";

#check if the super reads pipeline finished successfully
	print FILE "if [[ ! -e work2/superReads.success ]];then\n";
	print FILE "echo \"Super reads failed, check super2.err and files in ./work2/\"\n";
	print FILE "exit\n";
	print FILE "fi\n";

#now, using read positions in super reads, we find out which mates got joined -- these are the ones that do not have the biotin in the middle, call them chimeric
	if(not(-e "chimeric_sj.txt")||$rerun_pe==1||$rerun_sj==1){
	    print FILE "filter_alt.pl outtie < work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt >  chimeric_sj.txt \n";
	    $rerun_sj=1;
	}

#we also do initial redundancy filtering here, based on positions of reads in suoer reads
	if(not(-e "redundant_sj.txt")||$rerun_pe==1||$rerun_sj==1){
	    print FILE "filter_redundancy.pl 2 < work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt > redundant_sj.txt\n";
	    $rerun_sj=1;
	} 

	print FILE "echo 'Chimeric/Redundant jump reads:';wc -l  chimeric_sj.txt redundant_sj.txt;\n";

#remove all chimeric and all redundant reads from sj.cor.fa
	if(not(-e "sj.cor.clean.rev.fa")||$rerun_pe==1||$rerun_sj==1){
	    print FILE "extractreads.pl <(cat chimeric_sj.txt redundant_sj.txt | perl -e '{
		while(\$line=<STDIN>){
		chomp(\$line);
		\$h{\$line}=1
		}
		open(FILE,\$ARGV[0]);
		while(\$line=<FILE>){
		chomp(\$line);
		print \$line,\"\\n\" if(not(defined(\$h{\$line})));
		}
		}' <(awk '{
			prefix=substr(\$1,1,2); 
			readnumber=int(substr(\$1,3));  
			if(readnumber\%2==0){
				last_readnumber=readnumber; 
				last_prefix=prefix;
			}else{
				if(last_readnumber==readnumber-1 && last_prefix==prefix){
					print prefix\"\"last_readnumber\"\\n\"prefix\"\"readnumber;
				}
			}

			}' work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt)) sj.cor.fa 1 | putReadsIntoGroupsBasedOnSuperReads --super-read-sequence-file work2/superReadSequences.fasta --read-placements-file work2/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt > sj.cor.clean.fa\n";

#here we perform another round of filtering bad mates

	print FILE "findReversePointingJumpingReads_bigGenomes.perl --jellyfish-hash-size \$JF_SIZE --kmer-step-size 5 --reads-file sj.cor.clean.fa --reads-for-kunitigs-file pe.cor.fa --reads-for-kunitigs-file sj.cor.fa --dir-to-change-to  work2.1 --dir-for-kunitigs work2.1 --min-kmer-len 41 --max-kmer-len 81 -t $NUM_THREADS --maxnodes 1000 --kmer-step-size 10 1>findReversePointingJumpingReads.err 2>&1 \n";
	print FILE "extractreads_not.pl work2.1/readsToExclude.txt sj.cor.clean.fa 1 > sj.cor.clean2.fa\n";
	print FILE "echo Found extra chimeric mates: \n";
	print FILE "wc -l work2.1/readsToExclude.txt\n";
        print FILE "rm -f sj.cor.clean.rev.fa\n";
        foreach my $v (@jump_info_array) {
               my @f        = split(" ", $v);
               my $if_innie = "";
               $if_innie    = " | reverse_complement " if($f[1]>0);
               print FILE "grep --text -A 1 '^>$f[0]' sj.cor.clean2.fa | grep --text -v '^\\-\\-' $if_innie >> sj.cor.clean.rev.fa\n";
               }
            $rerun_sj=1;
	}


#here we extend the jumping library reads if they are too short
        if(not(-e "sj.cor.ext.fa")||$rerun_pe==1||$rerun_sj==1){      
        $rerun_sj=1;
	if($EXTEND_JUMP_READS==1){
        print FILE "createSuperReadsForDirectory.perl -jumplibraryreads -minreadsinsuperread 1 -l \$KMER_J -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.sj.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.jump.fasta -t $NUM_THREADS -mikedebug work3 sj.cor.clean.rev.fa 1> super2.err 2>&1\n";

#check if the super reads pipeline finished successfully
        print FILE "if [[ ! -e work3/superReads.success ]];then\n";
        print FILE "echo \"Super reads failed, check super2.err and files in ./work2/\"\n";
        print FILE "exit\n";
        print FILE "fi\n";

        print FILE "ln -sf work3/superReadSequences.jumpLibrary.fasta sj.cor.ext.fa\n";
	}else{
	print FILE "ln -sf sj.cor.clean.rev.fa sj.cor.ext.fa\n";
	}
	}

#here we create the frg files for CA from the jump libraries: each jump library will contribute one jump frg file and one additional frg file of linking information from "chimers"
        print FILE "log 'Creating FRG files'\n";
	print FILE "rm -rf compute_jump_coverage.txt\n";
	
        foreach my $v (@jump_info_array) {
	    my @f = split(" ", $v);
	    print FILE "echo -n \"$f[1] \" >> compute_jump_coverage.txt\n";
	    print FILE "grep --text -A 1 '^>$f[0]' sj.cor.ext.fa | grep --text -v '^\\-\\-' > $f[0].tmp\n";
	    print FILE "error_corrected2frg $f[0] ",abs($f[1])," $f[2] 2000000000 $f[0].tmp | grep --text '^{LKG' |wc -l >> compute_jump_coverage.txt\n";
        }
	print FILE "JUMP_BASES_COVERED=`awk 'BEGIN{b=0}{b+=\$1*\$2;}END{print b}' compute_jump_coverage.txt`\n";
        print FILE "save JUMP_BASES_COVERED\n";

#here we reduce jump library coverage: we know the genome size (from k-unitigs) and JUMP_BASES_COVERED contains total jump library coverage :)
        foreach my $v (@jump_info_array) {
	    my @f = split(" ", $v);
	    $list_frg_files .= "$f[0].cor.clean.frg ";
	    print FILE "grep --text -A 1 '^>$f[0]' sj.cor.ext.fa | grep --text -v '^\\-\\-' | sample_mate_pairs.pl $LIMIT_JUMP_COVERAGE `perl -e 'print int('\$JUMP_BASES_COVERED'/'\$ESTIMATED_GENOME_SIZE'/1.6)'` 1 > $f[0].tmp\n";
	    print FILE "error_corrected2frg $f[0] ",abs($f[1])," $f[2] 2000000000 $f[0].tmp > $f[0].cor.clean.frg\n";
	    print FILE "rm -f $f[0].tmp\n";
	}
    }

###done with super reads and filtering for jump###
    print FILE "\n";
##super reads for PE###

    print FILE "log 'Computing super reads from PE '\n";

#create super reads from PE    
    if($rerun_pe==1|| not(-e "work1")){
	print FILE "rm -rf work1\n";
	$rerun_pe=1;
    }

    print FILE "createSuperReadsForDirectory.perl -l \$KMER -mean-and-stdev-by-prefix-file meanAndStdevByPrefix.pe.txt -kunitigsfile guillaumeKUnitigsAtLeast32bases_all.fasta -t $NUM_THREADS -mikedebug work1 pe.cor.fa 1> super1.err 2>&1\n";

#check if the super reads pipeline finished successfully
    print FILE "if [[ ! -e work1/superReads.success ]];then\n";
    print FILE "echo \"Super reads failed, check super1.err and files in ./work1/\"\n";
    print FILE "exit\n";
    print FILE "fi\n";

    if($USE_LINKING_MATES==1){
#now we extract those PE mates that did not end up in the same super read -- we call them linking mates, they will be useful for scaffolding
	if(not(-e "pe.linking.fa")||$rerun_pe==1){
	    print FILE "extractreads.pl <( awk 'BEGIN{last_readnumber=-1;last_super_read=\"\"}{readnumber=int(substr(\$1,3));if(readnumber%2>0){readnumber--}super_read=\$2;if(readnumber==last_readnumber){if(super_read!=last_super_read){print read;print \$1;}}else{read=\$1;last_super_read=\$2}last_readnumber=readnumber}' work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt )  pe.cor.fa 1 > pe.linking.fa\n";
	    $rerun_pe=1;
	}
    print FILE "NUM_LINKING_MATES=`wc -l pe.linking.fa | perl -ane '{print int(\$F[0]/2)}'`\n";
    print FILE "MAX_LINKING_MATES=`perl -e '{print int('\$ESTIMATED_GENOME_SIZE'/100)}'`\n";
    
#create frg files for PE data
	foreach my $v (@pe_info_array){
	    my @f=split(/\s+/,$v);
	    $list_frg_files .= "$f[0].linking.frg ";
	    if(not(-e "$f[0].linking.frg")||$rerun_pe==1){
		print FILE "grep --text -A 1 '^>$f[0]' pe.linking.fa | grep --text -v '^\\-\\-' | sample_mate_pairs.pl \$MAX_LINKING_MATES \$NUM_LINKING_MATES 1 > $f[0].tmp\n";
		print FILE "error_corrected2frg $f[0] $f[1] $f[2] 2000000000 $f[0].tmp > $f[0].linking.frg\n";
		print FILE "rm $f[0].tmp\n";
	    }
	}
	print FILE "echo -n 'Linking PE reads ';\ncat ??.linking.frg |grep --text '^{FRG' |wc -l;\n";
    }

#create frg file for super reads
    if(not(-e "superReadSequences_shr.frg")||$rerun_pe==1){
	print FILE "cat work1/superReadSequences.fasta | create_sr_frg.pl 2>renamed_sr.txt | fasta2frg.pl super >  superReadSequences_shr.frg\n";
    }

###done with super reads for PE###
    print FILE "\n";
}

###Celera Assembler###
if(not(-e "CA/9-terminator/genome.qc")|| $rerun_pe || $rerun_sj){
    print FILE "\nlog 'Celera Assembler'\n";
    if($rerun_sj==1||$rerun_pe==1){
	print FILE "rm -rf CA\n";
    }

#this if statement is here because if OTHER frg is specified, we will have to do OBT+ECR, it will slow us down, but it has to be done :(
    my ($ovlMerSize, $other_parameters);
        if(@other_info_array > 0){
            $ovlMerSize=22;
            $other_parameters="doFragmentCorrection=1 doOverlapBasedTrimming=1 doExtendClearRanges=1 ovlMerSize=22";
        }else{
            $ovlMerSize=30;
            $other_parameters="doFragmentCorrection=0 doOverlapBasedTrimming=0 doExtendClearRanges=0 ovlMerSize=30";
        }

    if(not(-d "CA/7-0-CGW")|| $rerun_pe || $rerun_sj){
###figure out the optimal parameters for CA###
	print FILE "TOTAL_READS=`cat  *.frg |grep --text '^{FRG'|wc -l`\n";
        print FILE "save TOTAL_READS\n";
	print FILE "ovlRefBlockSize=`perl -e '\$s=int('\$TOTAL_READS'/8); if(\$s>100000){print \$s}else{print \"100000\"}'`\n";
        print FILE "save ovlRefBlockSize\n";
	print FILE "ovlHashBlockSize=`perl -e '\$s=int('\$TOTAL_READS'/80); if(\$s>10000){print \$s}else{print \"10000\"}'`\n";
        print FILE "save ovlHashBlockSize\n";
	print FILE "ovlCorrBatchSize=\$ovlHashBlockSize\n";
        print FILE "save ovlCorrBatchSize\n";
####done figuring out CA parameters###

#estimating mer threshold for overlapper to cover 90% of all distinct k-mers
	if(not(-d "CA/genome.ovlStore")|| $rerun_pe || $rerun_sj){
	    print FILE "ovlMerThreshold=`jellyfish-2.0 histo -t $NUM_THREADS k_u_hash_0 | awk '{thresh=75;if(\$1>1) {dist+=\$2;if(dist>int(\"'\$ESTIMATED_GENOME_SIZE'\")*0.98&&flag==0){if(\$1>thresh) thresh=\$1;flag=1}}}END{print thresh}'`\n";
	    print FILE "echo ovlMerThreshold=\$ovlMerThreshold\n\n";
	}

#filter out non-junction fragments

	if(@jump_info_array > 0){
	    if(not(-e "CA/4-unitigger-filter/gkp.edits.msg") || $rerun_pe || $rerun_sj){
		print FILE "runCA  gkpFixInsertSizes=0 $CA_PARAMETERS jellyfishHashSize=\$JF_SIZE ovlRefBlockSize=\$ovlRefBlockSize ovlHashBlockSize=\$ovlHashBlockSize ovlCorrBatchSize=\$ovlCorrBatchSize utgErrorRate=0.03 merylMemory=8192 stopAfter=unitigger ovlMerThreshold=\$ovlMerThreshold bogBreakAtIntersections=0 unitigger=bog bogBadMateDepth=1000000 -p genome -d CA merylThreads=$NUM_THREADS frgCorrThreads=1 frgCorrConcurrency=$NUM_THREADS cnsConcurrency=$NUM_THREADS ovlCorrConcurrency=$NUM_THREADS ovlConcurrency=$NUM_THREADS ovlThreads=1 $other_parameters superReadSequences_shr.frg $list_frg_files  1> runCA0.out 2>&1\n\n";


		print FILE "if [[ ! -e CA/4-unitigger/unitigger.err ]];then\n";
		print FILE "echo \"CA failed, check output under CA/ and runCA0.out\"\n";
		print FILE "exit\n";
		print FILE "fi\n";

		print FILE "cd CA/\nmv 4-unitigger 4-unitigger-filter\ncd 4-unitigger-filter\ngrep --text '^>' ../../sj.cor.ext.fa |awk '{print substr(\$1,2)}' > sj.uid\nfilter_library.sh ../ genome sj.uid\n";
		print FILE "cat genome.chimeric.uid |awk '{print \"frg uid \"\$1\" mateiid 0\"}'  > gkp.edits.msg\n";
		print FILE "echo -n \"Found additional non-junction reads: \"\nwc -l gkp.edits.msg\n";
		print FILE "gatekeeper --edit gkp.edits.msg ../genome.gkpStore 1>gatekeeper.err 2>&1\n";
		print FILE "cd ../\nrm -rf *.tigStore\ncd ../\n\n";
		print FILE "\n";
	    }
	    print FILE "if [[ -e \"CA/4-unitigger-filter/gkp.edits.msg\" ]];then\n";
	    print FILE "echo \"Filter success\"\n";
	    print FILE "else\n";
	    print FILE "echo \"Filtering failed, check output under CA/4-unitigger-filter/ and runCA0.out\"\n";
	    print FILE "exit\n";
	    print FILE "fi\n";
	}

	if(not(-e "CA/5-consensus/consensus.success")|| $rerun_pe || $rerun_sj){
	    print FILE "runCA ovlMerThreshold=\$ovlMerThreshold gkpFixInsertSizes=0 $CA_PARAMETERS jellyfishHashSize=\$JF_SIZE ovlRefBlockSize=\$ovlRefBlockSize ovlHashBlockSize=\$ovlHashBlockSize ovlCorrBatchSize=\$ovlCorrBatchSize stopAfter=consensusAfterUnitigger unitigger=bog -p genome -d CA merylThreads=$NUM_THREADS frgCorrThreads=1 frgCorrConcurrency=$NUM_THREADS cnsConcurrency=$NUM_THREADS ovlCorrConcurrency=$NUM_THREADS ovlConcurrency=$NUM_THREADS ovlThreads=1 $other_parameters superReadSequences_shr.frg $list_frg_files   1> runCA1.out 2>&1\n";

	    print FILE "if [[ -e \"CA/4-unitigger/unitigger.err\" ]];then\n";
	    print FILE "echo \"Overlap/unitig success\"\n";
	    print FILE "else\n";
	    print FILE "echo \"Overlap/unitig failed, check output under CA/ and runCA1.out\"\n";
	    print FILE "exit\n";
	    print FILE "fi\n";

#we now recompute the A-stat for the unitigs based on positions of PE reads in the super-reads
	    print FILE "recompute_astat_superreads.sh genome CA \$PE_AVG_READ_LENGTH work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt\n";

#here we filter for repetitive kmers in the unique unitigs
	    print FILE "NUM_SUPER_READS=`cat superReadSequences_shr.frg $tmplist | grep --text '^{FRG' |wc -l`\n";
            print FILE "save NUM_SUPER_READS\n";
	    print FILE "cd CA\n";
	    print FILE "tigStore -g genome.gkpStore -t genome.tigStore 2 -d layout -U | tr -d '-' | awk 'BEGIN{print \">unique unitigs\"}{if(\$1 == \"cns\"){seq=\$2}else if(\$1 == \"data.unitig_coverage_stat\" && \$2>=5){print seq\"N\"}}' | jellyfish-2.0 count -L 2 -C -m $ovlMerSize -s \$ESTIMATED_GENOME_SIZE -t $NUM_THREADS -o unitig_mers /dev/fd/0\n";
	    print FILE "cat <(overlapStore -b 1 -e \$NUM_SUPER_READS -d genome.ovlStore  | awk '{if(\$1<'\$NUM_SUPER_READS' && \$2<'\$NUM_SUPER_READS') print \$0}'|filter_overlap_file -t $NUM_THREADS <(gatekeeper -dumpfastaseq genome.gkpStore ) unitig_mers /dev/fd/0) <(overlapStore -d genome.ovlStore | awk '{if(\$1>='\$NUM_SUPER_READS' || \$2>='\$NUM_SUPER_READS') print \$1\" \"\$2\" \"\$3\" \"\$4\" \"\$5\" \"\$6\" \"\$7}')  |convertOverlap -b -ovl > overlaps.ovb\n";
	    print FILE "rm -rf 4-unitigger 5-consensus genome.tigStore genome.ovlStore\n";
	    print FILE "overlapStore -c genome.ovlStore -M 4096 -t $NUM_THREADS -g genome.gkpStore overlaps.ovb 1>overlapstore.err 2>&1\n";
	    print FILE "cd ..\n";
	    
#and now we rerun the assembler
	    print FILE "runCA ovlMerThreshold=\$ovlMerThreshold gkpFixInsertSizes=0 $CA_PARAMETERS jellyfishHashSize=\$JF_SIZE ovlRefBlockSize=\$ovlRefBlockSize ovlHashBlockSize=\$ovlHashBlockSize ovlCorrBatchSize=\$ovlCorrBatchSize stopAfter=consensusAfterUnitigger unitigger=bog -p genome -d CA merylThreads=$NUM_THREADS frgCorrThreads=1 frgCorrConcurrency=$NUM_THREADS cnsConcurrency=$NUM_THREADS ovlCorrConcurrency=$NUM_THREADS ovlConcurrency=$NUM_THREADS ovlThreads=1 $other_parameters superReadSequences_shr.frg $list_frg_files   1> runCA2.out 2>&1\n";

	    print FILE "if [[ -e \"CA/4-unitigger/unitigger.err\" ]];then\n";
	    print FILE "echo \"Overlap/unitig success\"\n";
	    print FILE "else\n";
	    print FILE "echo \"Overlap/unitig failed, check output under CA/ and runCA2.out\"\n";
	    print FILE "exit\n";
	    print FILE "fi\n";
#now we check if the unitig consensus which is sometimes problematic, failed, and fix the unitigs

	    print FILE "if [[ -e \"CA/5-consensus/consensus.success\" ]];then\n";
	    print FILE "echo \"Unitig consensus success\"\n";
	    print FILE "else\n";
	    print FILE "echo \"Fixing unitig consensus...\"\n";
	    print FILE "mkdir CA/fix_unitig_consensus\n";
	    print FILE "cd CA/fix_unitig_consensus\n";
	    print FILE "cp `which fix_unitigs.sh` .\n";
	    print FILE "./fix_unitigs.sh genome \n";
	    print FILE "cd ../../\n";
	    print FILE "fi\n";

#we now recompute the A-stat for the unitigs based on positions of PE reads in the super-reads
	    print FILE "recompute_astat_superreads.sh genome CA \$PE_AVG_READ_LENGTH work1/readPlacementsInSuperReads.final.read.superRead.offset.ori.txt\n";
	}
    }

#and we continue into the scaffolder...
    print FILE "runCA $CA_PARAMETERS unitigger=bog -p genome -d CA cnsConcurrency=$NUM_THREADS computeInsertSize=0 $other_parameters 1>runCA3.out 2>&1\n";

    print FILE "if [[ -e \"CA/9-terminator/genome.qc\" ]];then\n";
    print FILE "echo \"CA success\"\n";
    print FILE "else\n";
    print FILE "echo \"CA failed, check output under CA/ and runCA3.out\"\n";
    print FILE "exit\n";
    print FILE "fi\n";
}
#here we close gaps in scaffolds:  we use create_k_unitigs allowing to continue on count 1 sequence and then generate fake reads from the 
#end sequences of contigs that are next to each other in scaffolds, and then use super reads software to close the gaps for k=17...31
if($CLOSE_GAPS){

    print FILE "log 'Gap closing'\n";
    my $reads_argument= join(" ", map { "--reads-file '$_'" } (@pe_files, @sj_files));

    print FILE "closeGapsLocally.perl -s $JF_SIZE --Celera-terminator-directory CA/9-terminator $reads_argument --output-directory CA/10-gapclose --min-kmer-len 17 --max-kmer-len \$((\$PE_AVG_READ_LENGTH-5)) --num-threads $NUM_THREADS --contig-length-for-joining \$((\$PE_AVG_READ_LENGTH-1)) --contig-length-for-fishing 200 --reduce-read-set-kmer-size 21 1>gapClose.err 2>&1\n";
    print FILE "if [[ -e \"CA/10-gapclose/genome.ctg.fasta\" ]];then\n";
    print FILE "echo \"Gap close success. Output sequence is in CA/10-gapclose/genome.\{ctg,scf\}.fasta\"\n";
    print FILE "else\n";
    print FILE "echo \"Gap close failed, you can still use pre-gap close files under CA/9-terminator/. Check gapClose.err for problems.\"\n";
    print FILE "exit\n";
    print FILE "fi\n";
}

###Done !!!! Hoorayyyy!!! :)###
print FILE "log 'All done'\n";

close(FILE);
chmod 0755, $assembly_script;
print "done.\nexecute $assembly_script to run the assembly\n";


